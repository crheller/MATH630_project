---
title: "EDA - P3"
author: "Charlie Heller and Jyoti Tyagi"
date: "November 25, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Final Project, P3 - Exploratory Data Analysis


#### Finish tidying data
Per instructor feedback (pasted below) there are a few tweaks left that we need to make in order to tidy our data. We'll address these points first, then conduct our EDA

Good start, but you missed a couple important points: 

1) Your data is not yet tidy. Tidy means one observation per row, not one subject with a number of similar observations. As the data is currently formatted, it will be impossible for you to use the tidy or infer pipelines to explore or analyze your data. You'll need to "gather" the many columns into something approximately like:

        subject_id, pre_or_post, decorated_or_sparse, lesson, [distraction_type], result

Note: It's reasonable to leave the test scores and time-off-task in two tables, since the time-off-task has many subtypes. However, you may need to merge them (after tidying and summarizing) for some of your analyses.

2) In addition, you should be using the raw data, dropping any summary columns or tables and re-creating them (if needed) using the raw data and R. This would also result in a much shorter code book.

##### Tidy the data
We'll start by loading the data. We'll use the same function (defined below) from our last submission to read this back in.

* First, load libraries
```{r echo=TRUE, eval=TRUE}
library(readxl)
library(tidyverse)
```

* define loading function
```{r echo=TRUE, eval=TRUE}
read_excel_allsheets <- function(filename, tibble = TRUE) {
    sheets <- readxl::excel_sheets(filename)
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X, skip=2))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}
```

* load the data
```{r echo=TRUE, eval=TRUE}
data_tables <- read_excel_allsheets(here::here("Data", "vis_att_data.xlsx"))
```

* okay, now we've loaded the data into a list of dataframes. The first dataframe is the codebook, and the second is the summary table - as per instructor feedback, let's forget about those for now and work on tidying the raw data.


* The raw data (list elements 3 through 6) contains 1) pre and post test scores for each lesson and each classroom condition and 2) the total time spent off task for each of the classroom conditions/lessons, divided based on the type of off task behvior (self-distraction, peer distraction etc.).

* Because the list of options for time off task is so cumbersome, let's create two tidy data frames, one for test scores and one for total time off task. We'll first work on the test scores.

First, tidy each separately. We will leave condition to act as the "lesson" column. No need to parse the string now, as we can do it later if it really becomes necessary.
```{r echo=TRUE, eval=TRUE}
pre_df <- 
  janitor::clean_names(data_tables$`Pre-Test Scores by Lesson`) %>%
  select(-number, -x_1) %>%
  gather(condition, score, pre_test_plate_tectonics_sparse_classroom:total_pre_test_scores_decorated_classroom) %>%
  mutate(pre.post = ifelse(stringr::str_detect(condition, 'pre'), "pre", "post")) %>%
  mutate(sparse.decorated = ifelse(stringr::str_detect(condition, 'sparse'), "sparse", ifelse(stringr::str_detect(condition, 'decorated'), "decorated", NA)))
head(pre_df)
```

```{r echo=TRUE, eval=TRUE}
post_df <- 
  janitor::clean_names(data_tables$`Post-Test Scores by Lesson`) %>%
  select(-number, -x_1) %>%
  gather(condition, score, post_test_plate_tectonics_sparse_classroom:total_post_test_scores_decorated_classroom) %>%
  mutate(pre.post = ifelse(stringr::str_detect(condition, 'pre'), "pre", "post")) %>%
  mutate(sparse.decorated = ifelse(stringr::str_detect(condition, 'sparse'), "sparse", ifelse(stringr::str_detect(condition, 'decorated'), "decorated", NA)))
head(post_df)
```

Now, concatenate the pre and post test results
```{r echo=TRUE, eval=TRUE}
test_scores_df <- 
  rbind(pre_df, post_df)
head(test_scores_df)
```

Let's again replace "absent" entries with NA

```{r echo=TRUE, eval=TRUE}
test_scores_df[test_scores_df=="Absent"] <- NA
test_scores_df[test_scores_df=="absent"] <- NA
test_scores_df[test_scores_df=="Abent"] <- NA
```

Remove the participant (15) who was excluded from analyses due to absences
```{r echo=TRUE, eval=TRUE}
test_scores_df <- test_scores_df %>%
  filter(stringr::str_detect(id, "cs15")==FALSE)
```

And finally, lets remove any entries that correpond to "totals" and/or summaries.
```{r echo=TRUE, eval=TRUE}
test_scores_df <- test_scores_df %>%
  filter(stringr::str_detect(condition, "total")==FALSE)
```

Cool, now we've got a tidy data frame for our test scores. Note, that if we wanted to perform some sort of summary only over a given lesson, we'd use string logic on the column "condition" to effectivley pull only one lesson out.

Let's save this as a csv to `tidy_raw_test_scores`.
```{r echo=TRUE, eval=TRUE}
readr::write_csv(test_scores_df, here::here("Data", "tidy_raw_test_scores.csv"))
```


Now, let's do the same for the time spent off task.
```{r echo=TRUE, eval=TRUE}
# create df for sparse entries
sparse_df <- janitor::clean_names(data_tables$`TOT by Lesson Sparse condition`) %>%
  select(-number, -x_1) %>%
  gather(condition, score, plate_tec_self:sparse_total_time_off_task) %>%
  mutate(sparse.decorated = "sparse") %>%
  mutate(category = ifelse(stringr::str_detect(condition, 'self'), 'self', ifelse(stringr::str_detect(condition, 'peer'), 'peer', ifelse(stringr::str_detect(condition, 'environment'), 'envr', ifelse(stringr::str_detect(condition, 'other'), 'other', 'tot'))))) %>%
  mutate(class = ifelse(stringr::str_detect(condition, "tot")==FALSE, stringr::str_split(condition, "_", simplify=TRUE)[,1], 'tot'))

# create df for decorated entries
decorated_df <- janitor::clean_names(data_tables$`TOT by Lesson Decorated cond.`) %>%
  select(-number, -x_1) %>%
  gather(condition, score, stone_tools_self:decorated_total_time_off_task) %>%
  mutate(sparse.decorated = "decorated") %>%
   mutate(category = ifelse(stringr::str_detect(condition, 'self'), 'self', ifelse(stringr::str_detect(condition, 'peer'), 'peer', ifelse(stringr::str_detect(condition, 'environment'), 'envr', ifelse(stringr::str_detect(condition, 'other'), 'other', 'tot'))))) %>%
  mutate(class = ifelse(stringr::str_detect(condition, "tot")==FALSE, stringr::str_split(condition, "_", simplify=TRUE)[,1], 'tot'))

# combine the sparse and decorated dfs
time_off_task_df <- rbind(sparse_df, decorated_df)

# replace absent entries with NA
time_off_task_df[time_off_task_df=="Absent"] <- NA
time_off_task_df[time_off_task_df=="absent"] <- NA
time_off_task_df[time_off_task_df=="Abent"] <- NA

# remove participant 15 who was absent and excluded from analyses
time_off_task_df <- time_off_task_df %>%
  filter(stringr::str_detect(id, "cs15")==FALSE)

# remove any totals/summary columns
time_off_task_df <- time_off_task_df %>%
  filter(class!="tot", class!="decorated", class!="sparse")

# take a peek at our new tidy dataframe
head(time_off_task_df)

# save the tidy data frame
readr::write_csv(time_off_task_df, here::here("Data", "tidy_raw_time_off_task.csv"))
```


* alright, now that we've tidied the data, let's (re)load the tidy dataframe and perform our EDA

### Exploratory Data Analysis

First, load the data

```{r echo=TRUE, eval=TRUE}
test_scores <- dplyr::as_tibble(read.csv(here::here("Data", "tidy_raw_test_scores.csv")))
off_task <- dplyr::as_tibble(read.csv(here::here("Data", "tidy_raw_time_off_task.csv")))
```

#### 1) Issues encountered with the data
There weren't really any big issues. Some entries were listed as absent. During our data tidying, we converted these to NA to help us handle these cases smoothly with R. Also, the column names (now condition variable) are a little messy. It took a little work to parse them in order to make them more neat and construct atidy data frame. In particular, it's really a pain to parse the test scores in order to get the lesson title out, so we only did this for time off task. This shouldn't be too much of an issue, however. We can use string matching from the pacakage `stringr` on the column `condition` if we really wish to pull out data for one particular lesson.

#### 2) Descriptive statistics from the paper (and additional ones as necessary)

* The first descriptive statistic reported is the mean age of the children (5.37 years) as well as the number of male (12) and female (12) students. The raw data provided does not allow us to reproduce these summaries. In addition, we cannot reproduce the summaries of the student's demographic (race/ethnicity) information. However, we can confirm that the total number of participants was 24.

```{r echo=TRUE, eval=TRUE}
# there are 24 disitninct study participants
length(unique(off_task$id))
```
We only get 23 here because we have already removed the student who was exlcluded from analyses due to absences in the tidying step.

* The next notable summary statistic reported is the mean pre-test score. This is reported to be 22.7%. We can confirm this.

```{r echo=TRUE, eval=TRUE}
test_scores %>%
  filter((pre.post=="pre")) %>%
  summarize(mean_pre_test_score = 100*mean(score))
```

* For many of the anlayses in the paper, the authors present descriptive visualizations/summaries, then they quantify the differences they observe with statistical tests. We'll leave the quanitifcation for later (P4), but walk through the descriptive visualizations here.

* First, we'll repoduce the stats/figures for time off task as a function of classroom condition graph

The authors state that overall, children were on task 66.5% percent of the time. Let's confirm this without using the reported totals by the authors.

```{r echo=TRUE, eval=TRUE}
mean_tof <- 
  off_task %>%
  na.omit() %>%
  group_by(sparse.decorated, category) %>%
  mutate(score = as.numeric(as.character(score))) %>%
  summarize(means = mean(score), se = sd(score)/sqrt(length(score)))

# time ON-task across both conditions
100*(1 - 0.5 * (sum(filter(mean_tof, sparse.decorated=='decorated')$means) + sum(filter(mean_tof, sparse.decorated=='sparse')$means)))
```
As reported, students are ON task for about 66.3 percent of the time. We're not sure why this isn't coming out to exactly 66.5 as reported. 

Further, we see that the time off task is quite different for the two groups:

```{r echo=TRUE, eval=TRUE}
# time of task decorated
100*sum(filter(mean_tof, sparse.decorated=='decorated')$means)

# time of task sparse
100*sum(filter(mean_tof, sparse.decorated=='sparse')$means)
```
Again, these summaries stats don't exactly match those reported in the paper(38.58 and 28.42, respectively). Not sure why exactly why this is happening.

Finally, we can reproduce the summary plot for this, where time off task is split into each of its categories:
```{r echo=TRUE, eval=TRUE}
ggplot(mean_tof, aes(x=category, y=100*means)) + geom_bar(stat="identity") + facet_grid(~sparse.decorated) + 
  geom_errorbar(aes(ymin=100*(means-se), ymax=100*(means+se)),
                size=.3,
                width=.2)
```

* Next, the authors address pre- and post-test scores for both learning environments. They claim that the pre-test scores are statistically equivalent for the two environments (mean = .22 and mean = .23). They also claim that for the post test scores, there is a difference (.55 vs. mean = .42)

```{r echo=TRUE, eval=TRUE}
test_scores %>%
  select(score, pre.post, sparse.decorated) %>%
  na.omit() %>%
  group_by(pre.post, sparse.decorated) %>%
  summarize(means = 100*mean(score))
```

We see that again, this does seem to be the case. However, again our numbers are slightly different than the author's reported figures and it's unclear exactly why. Though, the difference is extremely small and is altogether not overly concerning. Perhaps it is due to a rounding error/discrepancy at some point in the data processing.

Though the authors don't include this, as part of an EDA exploring this relationship we might like to make a plot something like the following:

```{r echo=TRUE, eval=TRUE}
ts <- test_scores %>%
  na.omit()
ggplot2::ggplot(ts, aes(x=pre.post, y=100*score, color=sparse.decorated)) + geom_boxplot()
```

* Finally the authors investigate the relationship between time spent off task and learning. To do this, they first report the correlation between the mean post test scores and time off task. Therefore, they averaged each child's time off task and each child's post test score in the decorated/sparse conditions, ran the correlation, and found a negative correlation of -0.5. We repeat this analysis here along with the scatter plot visualization of this relationship that they present in the paper.

```{r echo=TRUE, eval=TRUE}
# calculate the mean time off task overall by student id. This involves a couple of steps

# first, calculate total time off task in decorated condition
tot_time_off_task_dec <- off_task %>%
  filter(sparse.decorated=="decorated") %>%
  select(id, category, score) %>%
  group_by(id, category) %>%
  na.omit() %>%
  summarize(means=mean(score)) %>%
  summarize(sums=100*sum(means))

# next, calculate the total time off task in the sparse condition
tot_time_off_task_spar <- off_task %>%
  filter(sparse.decorated=="sparse") %>%
  select(id, category, score) %>%
  group_by(id, category) %>%
  na.omit() %>%
  summarize(means=mean(score)) %>%
  summarize(sums=100*sum(means))

# Finally, compute the mean time off task overall
mean_time_off_task <- dplyr::left_join(tot_time_off_task_spar, tot_time_off_task_dec, by="id") %>%
  group_by(id) %>%
  summarize(means=mean(sums.x, sums.y))

# calculate the mean post-test score 
mean_post_test_scores <- test_scores %>%
  filter(pre.post=="post") %>%
  filter(stringr::str_detect(condition, "total")==FALSE) %>%
  select(id, score) %>%
  group_by(id) %>%
  na.omit() %>%
  summarize(means=100*mean(score))

# merge the two dataframes on id to make sure the values are matched correctly
df_merged <- dplyr::left_join(mean_post_test_scores, mean_time_off_task, by="id")

# plot the data and let ggpairs compute the correlation
df_merged %>% 
  select(means.y, means.x) %>%
  rename(mean_post_test_scores=means.y, mean_time_off_task=means.x) %>%
  GGally::ggpairs()
```

We see that there is clearly a negative relationship between the two variables, however, we notice a couple of differences in our results compared with those reported in the paper. 

* Firstly, we see a stronger correlation (-0.54) than the authors report (-0.5)

* Secondly, we noticed that it seems like the authors mislabeled the x and y axis of their scatter plot. We have corrected that in our plot above.

It is important to note, we don't think the discrepancy in our results is due to an error in calculations made on our part. In fact, we double-checked and found that our totals computed above agree exactly with the totals reported in the data file that came with the paper. Therefore, it is quite puzzling why we see this difference and it's unclear exactly what was plotted by the authors.

#### 3) Issues identified with the data
As discussed throughout the EDA above, we noticed that many of our values did not match exactly with those reported in the paper. This is strange. We explictly went back and check that the totals/summaries calculated with our R code match those reported in the author's data exactly. Therefore, it's unclear at this point exactly why we see a discrepancy between our statistics and theirs.

That being said, all the trends the author's observed are very clearly present in our analysis and most of the discrepancies we observed were extrememly minor and could potentially be attributed to numerical rounding differences between our approach and theirs. The only potential worrying point is the very last part of the EDA in which our correlation, and graph, appear notably different than what the author's report. Again, we checked that the values reported by the authors (in the publicly available summary data) match exaclty with the data we are plotting and presenting above, thus we don't think this is due to an error in our analysis. That being said, the trend we observe is clearly the same as what's presented in the paper so big picture-wise, this shouldn't dramatically affect our ability to reroduce/evaluate their result moving forward, but it's definitely worth being aware of.